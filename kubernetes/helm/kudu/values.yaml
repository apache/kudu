# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# Place to declare variables which will be passed to helm templates.
# Below are defaults values for Kudu Cluster Setup.

Component: "kududb"
Image:
  repository: "apache/kudu"
  tag: latest
  pullPolicy: IfNotPresent

# NOTE: WALs and data directories will be placed in separate volumes if more
# than one is available. If only one is available, they will be placed in the
# same volume. Thus, users should avoid switching between a single-volume
# deployment and multi-volume deployments, as that would move the data
# directory location from /mnt/disk0 to /mnt/disk1,/mnt/disk2,..., and servers
# would be unable to find their existing data directory in /mnt/disk0!
storage:
  master:
    count: 3
    size: 5Gi
    storageClass: standard
  tserver:
    count: 3
    size: 5Gi
    storageClass: standard

serviceEndpoints:
  - name: "kudu-master-ui"
    type: NodePort
    app: "kudu-master"
    ports:
      ui: "8050"
      rpc-port: "8051"

Services:
  - name: "kudu-masters"
    label: "kudu-master"
    ports:
      ui: "8050"
      rpc-port: "8051"

  - name: "kudu-tservers"
    label: "kudu-tserver"
    ports:
      ui: "7050"
      rpc-port: "7051"

resource:
  master:
    requests:
      cpu: 1
      memory: 0.5Gi
    limits:
      cpu: 1
      memory: 0.5Gi
  tserver:
    requests:
      cpu: 1
      memory: 1Gi
    limits:
      cpu: 1
      memory: 1Gi

replicas:
  master: 3
  tserver: 3

partition:
  master: 0
  tserver: 0

enableNodePort: True

NetworkPolicy:
  Enabled: false

PodManagementPolicy: Parallel

isMultiAz: False

domainName: "cluster.local"

nodeSelector: {}

resources: {}

affinity: {}

tolerations: []
